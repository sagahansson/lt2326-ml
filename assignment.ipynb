{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffbb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "a1dir = \"../../../scratch/lt2326-h21/a1\"\n",
    "imgs = os.listdir(a1dir+'/images')\n",
    "\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756fb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(direc):\n",
    "    \n",
    "    df = pd.read_json(direc + \"/train.jsonl\", lines=True)\n",
    "    imgs = os.listdir(direc+'/images')\n",
    "    #print(df.columns)\n",
    "    df =  df[df['file_name'].isin(imgs)]\n",
    "    df = df.drop(['ignore', 'image_id', 'height', 'width'], axis=1)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_meta(a1dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this literally doesn't even take a second so no worries\n",
    "def get_bboxes(df, k=None):\n",
    "    \n",
    "    if k is not None:\n",
    "        df = df.sample(k, random_state=42)\n",
    "    \n",
    "    all_bboxes = {}\n",
    "    for file in df.iterrows():\n",
    "        img_bboxes = [] # bboxes per image\n",
    "        for sign in file[1]['annotations']:\n",
    "            for d in sign:\n",
    "                if d['is_chinese']:\n",
    "                    x, y, w, h = d['adjusted_bbox']\n",
    "                    xmin = int(math.floor(x))\n",
    "                    xmax = int(math.ceil(x + w))\n",
    "                    ymin = int(math.floor(y))\n",
    "                    ymax = int(math.ceil(y + h))\n",
    "                    bbox = np.array([xmin, ymin, xmax, ymax])\n",
    "                    img_bboxes.append(bbox)\n",
    "\n",
    "\n",
    "        all_bboxes[file[1]['file_name']] = np.array(img_bboxes)\n",
    "    \n",
    "    return all_bboxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "all_bboxes = get_bboxes(df)\n",
    "toc = time.perf_counter()\n",
    "print(f\"Finished in {toc - tic:0.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17944ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(bboxes=all_bboxes):\n",
    "    \n",
    "    print(f'Time now: {datetime.datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "    \n",
    "    p =  [(img_i0, img_i1) for img_i0, img_i1 in np.ndindex(2048, 2048)] # first two numbers of indices of each image\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    labelling = {}\n",
    "    count = 0\n",
    "    for fn, bbox in all_bboxes.items():\n",
    "        tac = time.perf_counter()\n",
    "        lab = ((p>=bbox[:,None,:2]) & (p<=bbox[:,None,2:])).all(2) # thanks https://stackoverflow.com/questions/62235257/determine-if-many-points-are-in-bounding-box\n",
    "        lab2 = lab.reshape(len(bbox), 2048, 2048).astype(int)\n",
    "        #lab2int = lab2.astype(int)\n",
    "        lab2intsumclip = np.clip(np.sum(lab2, axis = 0), 0, 1).reshape(2048, 2048, 1)\n",
    "        #lab2intsumreshape = lab2intsumclip.reshape(2048, 2048, 1)\n",
    "\n",
    "        labelling[fn] = lab2intsumclip\n",
    "        count += 1\n",
    "        tuc = time.perf_counter()\n",
    "        print(f\"Finished image {fn} in {tuc - tac:0.4f} seconds, {count}/{len(all_bboxes)}\")\n",
    "\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    final_time = str(datetime.timedelta(seconds=round(toc - tic)))\n",
    "    s_per_img = (toc - tic)/len(all_bboxes)\n",
    "    \n",
    "    print(f\"Finished in {final_time}\\nAvg. time per img: {s_per_img} seconds.\")\n",
    "    print(f'Finished at: {datetime.datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "    \n",
    "    return labelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33028ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#labelling = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b115b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(labelling, open(\"labelling_alsotrash.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38245e36",
   "metadata": {},
   "source": [
    "## Start running here if you have labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e70cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling = pickle.load(open(\"labelling_small.p\", \"rb\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcc56fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = labelling.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs(filenames, datadir, imgs):\n",
    "    return {x : np.array(Image.open(\"{}/{}\".format(datadir, x)).convert('RGB')) for x in filenames if x in imgs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fc8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_imgs(file_names, a1dir+'/images', imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dba33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_arrs = list(labelling.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f003b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arrs = list(data.values()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a5dcc",
   "metadata": {},
   "source": [
    "## PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f11a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda:2')\n",
    "\n",
    "# training hyperparameters\n",
    "batch_size = 4\n",
    "lr = 0.01\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387bc22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(img_arrs, label_arrs, train_size=0.8, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size=0.5, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataload_train = DataLoader(list(zip(X_train, y_train)), batch_size=batch_size, shuffle=True)\n",
    "dataload_test = DataLoader(list(zip(X_test, y_test)), batch_size=batch_size, shuffle=True)\n",
    "dataload_val = DataLoader(list(zip(X_val, y_val)), batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Lenet(nn.Module):\n",
    "    def __init__(self, outsize):\n",
    "        super(Lenet, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(            \n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),      # [B, 3, 2048, 2048] -> [B, 6, 2044, 2044]\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=3),                                  # [B, 6, 2044, 2044] -> [B, 6, 681, 681]\n",
    "                        \n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),     # [B, 6, 681, 681] -> [B, 16, 677, 677]\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),                                  # [B, 16, 677, 677] -> [B, 16,  338, 338]\n",
    "            \n",
    "            nn.Conv2d(in_channels=16, out_channels=12, kernel_size=5),    # [B, 16,  338, 338] -> [B, 12, 334, 334]\n",
    "            nn.Tanh(),            \n",
    "            nn.AvgPool2d(kernel_size=3),                                  # [B, 12, 334, 334] -> [B, 12, 111, 111]\n",
    "            #PrintLayer(),            \n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=111*111*12, out_features=1000), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1000, out_features=outsize),\n",
    "            nn.Sigmoid()\n",
    "        )        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x) \n",
    "        #print(x.shape)\n",
    "        pred = self.fc(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b314830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(model, dataloader, model_num, device=torch.device('cuda:2'), lr=0.01, e=5):    \n",
    "    \n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    model.train()\n",
    "    \n",
    "    upsample = nn.Upsample(size=2048*2048)\n",
    "    \n",
    "    print('Training')\n",
    "    for e in range(e):\n",
    "        total_loss = 0\n",
    "        for i , data in enumerate(dataloader):\n",
    "            \n",
    "            X, y = data\n",
    "            X = X.permute(0,3,1,2).float()\n",
    "            X, y = (X.to(device), y.to(device))\n",
    "            pred = model(X)\n",
    "            \n",
    "            \n",
    "            upsampled = upsample(pred.unsqueeze(1))\n",
    "        \n",
    "            \n",
    "            loss = criterion(upsampled.reshape(y.shape), y.float())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            print(total_loss/(i+1), end='\\r')            \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            optimizer.zero_grad()\n",
    "        print()\n",
    "    print(f'Saving model{model_num}')\n",
    "    # save model\n",
    "    #torch.save(model, f\"model{model_num}.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc96961",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = Lenet(250)\n",
    "train(net, dataload_train, '1', e=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3791abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test(m, dataloader, device=torch.device('cuda:2')):\n",
    "    \n",
    "    m = m.to(device)\n",
    "    mse = nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    batch_acc = 0\n",
    "    \n",
    "    upsample = nn.Upsample(size=2048*2048)\n",
    "    \n",
    "    m.eval()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        #print(i)\n",
    "        X, y = data\n",
    "        X = X.permute(0,3,2,1).float()\n",
    "        X, y = (X.to(device), y.to(device))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = m(X)            \n",
    "            \n",
    "        upsampled = upsample(pred.unsqueeze(1))\n",
    "        \n",
    "        loss = mse(upsampled.reshape(y.shape), y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        batch_acc += torch.sum((torch.round(upsampled.reshape(y.shape)) == y))\n",
    "        \n",
    "        #print(batch_acc, batch_acc2)\n",
    "        \n",
    "    accuracy = int(batch_acc) / ((i+1) * batch_size * 3*2048*2048)\n",
    "\n",
    "    print(f'Accuracy: {round(accuracy,2)}, Loss: {round(total_loss,2)}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdacdc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(net, dataload_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alexnet(nn.Module):\n",
    "  def __init__(self, outsize=250):\n",
    "    super(Alexnet, self).__init__()\n",
    "    self.feature_extraction = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3,  out_channels=6,  kernel_size=11,  stride=4,  padding=2,  bias=False),\n",
    "        PrintLayer(),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\n",
    "        \n",
    "        nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5, stride=1, padding=2, bias=False),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=0),\n",
    "        \n",
    "        nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Conv2d(in_channels=24, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3,  stride=2,  padding=0),\n",
    "        PrintLayer()\n",
    "    )\n",
    "    self.classifier = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(in_features=16*63*63, out_features=256), \n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(in_features=256,  out_features=256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(in_features=256,  out_features=outsize),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "  def forward(self, x):\n",
    "    x = self.feature_extraction(x)\n",
    "    #x = x.view(x.size(0), 256*6*6)\n",
    "    x = self.classifier(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8bf517",
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = Alexnet()\n",
    "train(alexnet, dataload_train, '1', e=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf5458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

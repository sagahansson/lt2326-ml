{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dffbb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import datetime\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "a1dir = \"../../../scratch/lt2326-h21/a1\"\n",
    "imgs = os.listdir(a1dir+'/images')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756fb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(direc):\n",
    "    \n",
    "    df = pd.read_json(direc + \"/train.jsonl\", lines=True)\n",
    "    imgs = os.listdir(direc+'/images')\n",
    "    df =  df[df['file_name'].isin(imgs)]\n",
    "    df = df.drop(['ignore', 'image_id', 'height', 'width'], axis=1)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_meta(a1dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9230ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bboxes(df, k=None):\n",
    "    \n",
    "    if k is not None:\n",
    "        df = df.sample(k, random_state=42)\n",
    "    \n",
    "    all_bboxes = {}\n",
    "    for file in df.iterrows():\n",
    "        img_bboxes = [] # bboxes per image\n",
    "        for sign in file[1]['annotations']:\n",
    "            for d in sign:\n",
    "                if d['is_chinese']:\n",
    "                    x, y, w, h = d['adjusted_bbox'] # thanks https://github.com/yuantailing/ctw-baseline/blob/master/classification/create_pkl.py#L20\n",
    "                    xmin = int(math.floor(x))\n",
    "                    xmax = int(math.ceil(x + w))\n",
    "                    ymin = int(math.floor(y))\n",
    "                    ymax = int(math.ceil(y + h))\n",
    "                    bbox = np.array([xmin, ymin, xmax, ymax])\n",
    "                    img_bboxes.append(bbox)\n",
    "\n",
    "\n",
    "        all_bboxes[file[1]['file_name']] = np.array(img_bboxes)\n",
    "    \n",
    "    return all_bboxes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bboxes = get_bboxes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17944ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(bboxes=all_bboxes):\n",
    "    \n",
    "    print(f'Time now: {datetime.datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "    \n",
    "    p =  [(img_i0, img_i1) for img_i0, img_i1 in np.ndindex(2048, 2048)] # first two numbers of indices of each image\n",
    "\n",
    "    tic = time.perf_counter()\n",
    "    labelling = {}\n",
    "    count = 0\n",
    "    for fn, bbox in all_bboxes.items():\n",
    "        tac = time.perf_counter()\n",
    "        # checks which points (p) are in the bounding boxes\n",
    "        lab = ((p>=bbox[:,None,:2]) & (p<=bbox[:,None,2:])).all(2) # thanks https://stackoverflow.com/a/62235347/14112047\n",
    "        \n",
    "        lab2 = lab.reshape(len(bbox), 2048, 2048).astype(int) # reshapes into as many bboxes the img has, converts from bool to binary\n",
    "        lab2intsumclip = np.clip(np.sum(lab2, axis = 0), 0, 1).reshape(2048, 2048, 1) # sums all bboxes for one img, clips at 1, more reshaping\n",
    "        \n",
    "\n",
    "        labelling[fn] = lab2intsumclip\n",
    "        count += 1\n",
    "        tuc = time.perf_counter()\n",
    "        print(f\"Finished image {fn} in {tuc - tac:0.4f} seconds, {count}/{len(all_bboxes)}\")\n",
    "\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    final_time = str(datetime.timedelta(seconds=round(toc - tic)))\n",
    "    s_per_img = (toc - tic)/len(all_bboxes)\n",
    "    \n",
    "    print(f\"Finished in {final_time}\\nAvg. time per img: {s_per_img} seconds.\")\n",
    "    print(f'Finished at: {datetime.datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "    \n",
    "    return labelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33028ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b115b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(labelling, open(\"labels_full.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38245e36",
   "metadata": {},
   "source": [
    "## Start running here if you have labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e70cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling = pickle.load(open(\"labels_full.p\", \"rb\")) # load either labels_full, -_half (422), or -_small (100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b9cc022",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = labelling.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bad9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs(filenames, datadir, imgs):\n",
    "    return {x : np.array(Image.open(\"{}/{}\".format(datadir, x)).convert('RGB')) for x in filenames if x in imgs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9fc8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_imgs(file_names, a1dir+'/images', imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dba33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_arrs = list(labelling.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f003b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arrs = list(data.values()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3bbc8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(img_arrs, label_arrs, train_size=0.8, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, train_size=0.5, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65a5dcc",
   "metadata": {},
   "source": [
    "## PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "297f11a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda:2')\n",
    "batch_size = 4\n",
    "lr = 0.01\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "128f3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataload_train = DataLoader(list(zip(X_train, y_train)), batch_size=batch_size, shuffle=True)\n",
    "dataload_test = DataLoader(list(zip(X_test, y_test)), batch_size=batch_size, shuffle=True)\n",
    "dataload_val = DataLoader(list(zip(X_val, y_val)), batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bee310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Lenet(nn.Module):\n",
    "    def __init__(self, outsize=250):\n",
    "        super(Lenet, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(            \n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5),      # [B, 3, 2048, 2048] -> [B, 6, 2044, 2044]\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=3),                                  # [B, 6, 2044, 2044] -> [B, 6, 681, 681]\n",
    "                        \n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),     # [B, 6, 681, 681] -> [B, 16, 677, 677]\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),                                  # [B, 16, 677, 677] -> [B, 16,  338, 338]\n",
    "            \n",
    "            nn.Conv2d(in_channels=16, out_channels=12, kernel_size=5),    # [B, 16,  338, 338] -> [B, 12, 334, 334]\n",
    "            nn.Tanh(),            \n",
    "            nn.AvgPool2d(kernel_size=3),                                  # [B, 12, 334, 334] -> [B, 12, 111, 111]      \n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=111*111*12, out_features=1000), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=1000, out_features=outsize),\n",
    "            nn.Sigmoid()\n",
    "        )        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x) \n",
    "        #print(x.shape)\n",
    "        pred = self.fc(x)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89c4ef1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Alexnet(nn.Module):\n",
    "  def __init__(self, outsize=250):\n",
    "    super(Alexnet, self).__init__()\n",
    "    self.cnn = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3,  out_channels=6,  kernel_size=11,  stride=4,  padding=2,  bias=False), # [B, 3, 2048, 2048] -> [B, 6, 511, 511]\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                               # [B, 6, 511, 511] -> [B, 6, 255, 255]\n",
    "        \n",
    "        nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5, stride=1, padding=2, bias=False),      # [B, 6, 255, 255] -> [B, 12, 255, 255]\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=2, padding=0),                                               # [B, 12, 255, 255] -> [B, 12, 127, 127]\n",
    "        \n",
    "        nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1, bias=False),     # [B, 12, 127, 127] -> [B, 24, 127, 127]\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Conv2d(in_channels=24, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),     # [B, 24, 127, 127] -> [B, 24, 127, 127]\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False),     # [B, 24, 127, 127] -> [B, 24, 127, 127]\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=3,  stride=2,  padding=0),                                             # [B, 24, 127, 127] -> [B, 16, 63, 63]\n",
    "    )\n",
    "    \n",
    "    self.avgpool = nn.AdaptiveAvgPool2d((6, 6))                                                         # [B, 16, 63, 63] -> [B, 16, 6, 6]\n",
    "    \n",
    "    self.fc = nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(in_features=16*6*6, out_features=256), \n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(in_features=256,  out_features=256),\n",
    "        nn.ReLU(inplace=True),\n",
    "        \n",
    "        nn.Linear(in_features=256,  out_features=outsize),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "  def forward(self, x):\n",
    "    x = self.cnn(x)\n",
    "    x = self.avgpool(x)\n",
    "    x = self.fc(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b314830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(m, dataloader, m_name, device=torch.device('cuda:2'), lr=0.01, e=5):    \n",
    "    \n",
    "    m = m.to(device)\n",
    "    optimizer = optim.Adam(m.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    m.train()\n",
    "    \n",
    "    upsample = nn.Upsample(size=2048*2048)\n",
    "    \n",
    "    print('TRAINING STARTED')\n",
    "    for e in range(e):\n",
    "        total_loss = 0\n",
    "        for i , data in enumerate(dataloader):\n",
    "            \n",
    "            X, y = data\n",
    "            X = X.permute(0,3,1,2).float()\n",
    "            X, y = (X.to(device), y.to(device))\n",
    "            pred = m(X)\n",
    "                        \n",
    "            upsampled = upsample(pred.unsqueeze(1))\n",
    "\n",
    "            loss = criterion(upsampled.reshape(y.shape), y.float())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            print(total_loss/(i+1), end='\\r')\n",
    "            \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        print()\n",
    "    print(f'Saving model {m_name}.')\n",
    "    # save m\n",
    "    #torch.save(m, f\"{m_name}.pt\")\n",
    "    print(f'Model {m_name} saved!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc96961",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = Lenet()\n",
    "train(lenet, dataload_train, 'lenet_alldata', e=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a8bf517",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING STARTED\n",
      "torch.Size([4, 16, 6, 6])\n",
      "torch.Size([4, 16, 6, 6])\n",
      "torch.Size([4, 16, 6, 6])\n",
      "torch.Size([4, 16, 6, 6])\n",
      "torch.Size([4, 16, 6, 6])\n",
      "torch.Size([4, 16, 6, 6])\n",
      "torch.Size([4, 16, 6, 6])\n",
      "torch.Size([4, 16, 6, 6])\n",
      "torch.Size([4, 16, 6, 6])\n",
      "0.7366041474872165\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1452027/1405266630.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0malexnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlexnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malexnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataload_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'alex_alldata'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1452027/758502722.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(m, dataloader, m_name, device, lr, e)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alexnet = Alexnet()\n",
    "train(alexnet, dataload_train, 'alex_alldata', e=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd2e355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def test(m, dataloader, device=torch.device('cuda:2')):\n",
    "    \n",
    "    m = m.to(device)\n",
    "    mse = nn.MSELoss()\n",
    "    total_loss = 0\n",
    "    batch_acc = 0\n",
    "    \n",
    "    upsample = nn.Upsample(size=2048*2048)\n",
    "    \n",
    "    m.eval()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        #print(i)\n",
    "        X, y = data\n",
    "        X = X.permute(0,3,2,1).float()\n",
    "        X, y = (X.to(device), y.to(device))\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = m(X)            \n",
    "            \n",
    "        upsampled = upsample(pred.unsqueeze(1))\n",
    "        \n",
    "        loss = mse(upsampled.reshape(y.shape), y)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        batch_acc += torch.sum((torch.round(upsampled.reshape(y.shape)) == y))\n",
    "        \n",
    "        #print(batch_acc, batch_acc2)\n",
    "        \n",
    "    accuracy = int(batch_acc) / ((i+1) * batch_size * 3*2048*2048)\n",
    "\n",
    "    print(f'Accuracy: {round(accuracy,5)}, Loss: {round(total_loss,5)}')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71bb53f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models trained on all the data\n",
    "lenet_alldata = torch.load(\"lenet_alldata.pt\")\n",
    "alexnet_alldata = torch.load(\"alex_alldata.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36f011fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.33159, Loss: 0.10957\n"
     ]
    }
   ],
   "source": [
    "test(lenet_alldata, dataload_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af857e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.33159, Loss: 0.10957\n"
     ]
    }
   ],
   "source": [
    "test(alexnet_alldata, dataload_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f103c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models trained on only 100 imgs\n",
    "lenet_halfdata = torch.load(\"lenet_halfldata.pt\")\n",
    "alexnet_halfdata = torch.load(\"alex_halfldata.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca195a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lenet_halfdata, dataload_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10bb80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(alexnet_halfdata, dataload_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f720698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models trained on only 100 imgs\n",
    "lenet_smalldata = torch.load(\"lenet_smalldata.pt\")\n",
    "alexnet_smalldata = torch.load(\"alex_smalldata.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc53d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(lenet_smalldata, dataload_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c657b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(alexnet_smalldata, dataload_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_model(m, x_test):\n",
    "    \n",
    "    random_x = random.choice(x_test)\n",
    "    reshaped_x = torch.tensor(np.expand_dims(np.swapaxes(random_x, 2, 0), 0)).float().to(device)\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        pred = m(reshaped_x)\n",
    "    \n",
    "    upsample = nn.Upsample(size=2048*2048)\n",
    "    upsampled = upsample(pred.unsqueeze(1))\n",
    "    reshaped_upsampled = upsampled.reshape(2048, 2048)\n",
    "    \n",
    "    \n",
    "    plt.imshow(random_x, interpolation=None)\n",
    "    plt.imshow(np.array(torch.round(reshaped_upsampled.cpu())), alpha=0.5, interpolation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca30a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_model(alexnet1, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539d07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_model(alexnet_alldata, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90880ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(y_train[0] == [1]) # made extra sure labels actually contain 1s and not only 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd027749",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_index = index[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(y_train[0].squeeze()[new_index] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e2cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0].squeeze()[3][950]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
